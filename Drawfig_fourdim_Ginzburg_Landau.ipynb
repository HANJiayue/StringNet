{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zTGC0ZGfaFvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtzE6__6VlfM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import matplotlib as mpl\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import pickle\n",
        "from scipy.io import loadmat\n",
        "import os\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device to train\")\n",
        "\n",
        "\n",
        "all_path=\"/content/drive/MyDrive/Colab_Notebooks/2023_mep/0120/\"\n",
        "path_m1=\"/content/drive/MyDrive/Colab_Notebooks/2023_mep/0120/d4_m1_k008/model_MEP_find_minimals_d4_m1_k008.pth\"\n",
        "path_p1=\"/content/drive/MyDrive/Colab_Notebooks/2023_mep/0120/d4_p1_k008/model_MEP_find_minimals_d4_p1_k008.pth\"\n",
        "\n",
        "\n",
        "mycase=\"ac_4d_6\"\n",
        "casenum=\"NBC_k008_beta10lg_6\"\n",
        "\n",
        "path_lg=all_path+casenum+\"/\"+\"lgloss\"+\".pkl\"\n",
        "\n",
        "plot_use_all=[]\n",
        "\n",
        "torch.set_printoptions(precision=10)\n",
        "\n",
        "\n",
        "model_name= all_path+casenum+\"/\"+\"model_MEP_\"+mycase+\"_\"+casenum+\".pth\"\n",
        "model_Parameters_name=model_name\n",
        "\n",
        "\n",
        "kappa=0.08\n",
        "load_model = True\n",
        "batches = 20000\n",
        "beta = 10\n",
        "learning_rate = 1e-4\n",
        "dimension = 1\n",
        "dn=100\n",
        "dnt=28\n",
        "\n",
        "x_dim=4\n",
        "\n",
        "\n",
        "\n",
        "alpha1=1\n",
        "alpha4=0\n",
        "alpha3=0.001\n",
        "alpha5=1\n",
        "\n",
        "\n",
        "\n",
        "def mkdir(path):\n",
        "  folder = os.path.exists(path)\n",
        "  if not folder:\n",
        "    os.makedirs(path)\n",
        "    print(\"---  new folder...  ---\")\n",
        "    print(\"---  OK  ---\")\n",
        "  else:\n",
        "    print(\"---  There is this folder!  ---\")\n",
        "\n",
        "\n",
        "def fig_loss_batch(plt_batch,loss_batch):\n",
        "    plt.figure(figsize=(5,4))\n",
        "    plt.plot(plt_batch,loss_batch,'b-')\n",
        "    plt.xlabel(\"Batches\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "\n",
        "def fig_cos(plt_batch,lg_batch,j):\n",
        "    fig = plt.figure(figsize=(5,4))\n",
        "    plt.plot(plt_batch,lg_batch,'b-')\n",
        "    plt.xlabel(\"Batches\")\n",
        "    plt.ylabel(\"$l_g$\")\n",
        "    if j == batches-500:\n",
        "      plt.savefig(all_path+casenum+\"/\"+\"lgloss\"+\".jpg\")\n",
        "\n",
        "def fig_countour(model):\n",
        "    x_plot_use=[0.25,0.5]\n",
        "    t_plot_use=[0.0,0.25,0.5,0.75,1.0]\n",
        "\n",
        "    x1 = np.linspace(0.001,0.999,dn,endpoint=True)\n",
        "    x2 = np.linspace(0.001,0.999,dn,endpoint=True)\n",
        "\n",
        "    xx1,xx2=np.meshgrid(x1,x2)\n",
        "    xx1=xx1.reshape((-1,1))\n",
        "    xx2=xx2.reshape((-1,1))\n",
        "\n",
        "    xx=np.hstack((xx1,xx2))\n",
        "\n",
        "    xx1=xx[:,0]\n",
        "    xx2=xx[:,1]\n",
        "\n",
        "    xx1=xx1.reshape(dn,dn)\n",
        "    xx2=xx2.reshape(dn,dn)\n",
        "\n",
        "\n",
        "    t_all=[r\"$s=0$\",r\"$s=\\frac{1}{4}$\",r\"$s=\\frac{1}{2}$\",r\"$s=\\frac{3}{4}$\",r\"$s=1$\"]\n",
        "\n",
        "\n",
        "    for t in t_plot_use:\n",
        "      fig2 = plt.figure(figsize=(6,6))\n",
        "      for k in range(len(x_plot_use)):\n",
        "        for l in range(len(x_plot_use)):\n",
        "          title_all=r\"$(x_1,x_2,$\"\n",
        "          x2=x_plot_use[k]*np.ones((dn*dn,1))\n",
        "          x3=x_plot_use[l]*np.ones((dn*dn,1))\n",
        "          tt=t*np.ones((dn*dn,1))\n",
        "          xxx=np.hstack((xx,x2))\n",
        "          xxxx=np.hstack((xxx,x3))\n",
        "          txxxx=np.hstack((tt,xxxx))\n",
        "          txxxx_tensor=Variable(torch.from_numpy(txxxx),requires_grad=True).to(device)\n",
        "          phi_tensor=model(txxxx_tensor)\n",
        "\n",
        "          phi=phi_tensor.cpu().detach().numpy()\n",
        "\n",
        "          phi_plot_sq=phi.reshape(dn,dn)\n",
        "\n",
        "          fig2.add_subplot(len(x_plot_use),len(x_plot_use),k*len(x_plot_use)+l+1)\n",
        "\n",
        "          picori=phi_plot_sq.reshape(dn,dn)\n",
        "          pic=np.zeros((dn,dn,3))\n",
        "\n",
        "          B=(np.sign(picori)+1)/2*picori\n",
        "          C=(np.sign(picori)-1)/2*picori\n",
        "\n",
        "          pic[:,:,0]=B\n",
        "          pic[:,:,-1]=C\n",
        "\n",
        "\n",
        "          plt.imshow(pic)\n",
        "          plt.xticks([])\n",
        "          plt.yticks([])\n",
        "\n",
        "          if k==0:\n",
        "            title_all=title_all+r\"$\\frac{1}{4},$\"\n",
        "          elif k==1:\n",
        "            title_all=title_all+r\"$\\frac{1}{2},$\"\n",
        "\n",
        "          if l==0:\n",
        "            title_all=title_all+r\"$\\frac{1}{4})$\"\n",
        "          elif l==1:\n",
        "            title_all=title_all+r\"$\\frac{1}{2})$\"\n",
        "\n",
        "          plt.title(title_all)\n",
        "          plt.xlabel(r\"$x_1$\")\n",
        "          plt.ylabel(r\"$x_2$\")\n",
        "\n",
        "\n",
        "      plt.savefig(\"dim4_k008_\"+\"t_\"+str(t)+\".pdf\")\n",
        "\n",
        "\n",
        "class NeuralNetwork_minimum(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork_minimum, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_tanh_stack = nn.Sequential(\n",
        "            nn.Linear(4,64),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(64, 64),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(64, 64),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(64, 64),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, s):\n",
        "        phi_pred = self.linear_tanh_stack(s)\n",
        "        return phi_pred\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self,p1,m1):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_tanh_stack = nn.Sequential(\n",
        "            nn.Linear(x_dim+1,100),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(100, 100),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(100, 100),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(100, 100),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(100, 1)\n",
        "        )\n",
        "        self.p1=p1\n",
        "        self.m1=m1\n",
        "\n",
        "\n",
        "    def forward(self, s):\n",
        "        x_pred = self.linear_tanh_stack(s)\n",
        "        ss=s[:,0]\n",
        "        ss=ss.reshape(-1,1)\n",
        "        xx=s[:,1:]\n",
        "\n",
        "        out=ss*(1-ss)*x_pred + (1-ss)*self.p1(xx) + ss*self.m1(xx)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "def train(model):\n",
        "    loss_batch=[]\n",
        "    plt_batch=[]\n",
        "    lg_batch=[]\n",
        "\n",
        "    if load_model:\n",
        "        model.load_state_dict(torch.load(model_Parameters_name))\n",
        "\n",
        "    fig_countour(model)\n",
        "    plt.show()\n",
        "\n",
        "    return\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__=='__main__':\n",
        "\n",
        "    net_p1=NeuralNetwork_minimum().to(device)\n",
        "    net_p1=net_p1.double()\n",
        "    net_p1.load_state_dict(torch.load(path_p1))\n",
        "\n",
        "    for p in net_p1.parameters():\n",
        "        p.requires_grad=False\n",
        "\n",
        "\n",
        "    net_m1=NeuralNetwork_minimum().to(device)\n",
        "    net_m1=net_m1.double()\n",
        "    net_m1.load_state_dict(torch.load(path_m1))\n",
        "\n",
        "\n",
        "    for p in net_m1.parameters():\n",
        "        p.requires_grad=False\n",
        "\n",
        "\n",
        "    mkdir(all_path+casenum+\"_energyfig/\")\n",
        "\n",
        "\n",
        "    model = NeuralNetwork(net_p1,net_m1).to(device)\n",
        "    model = model.double()\n",
        "\n",
        "    #model = train_pre(model)\n",
        "    train(model)\n",
        "\n"
      ]
    }
  ]
}