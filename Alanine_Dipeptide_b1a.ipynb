{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NztnN7zjrhRz"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJlxoB3wq5hL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import matplotlib as mpl\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "#-------------------------------------------------\n",
        "mycase=\"ad_4d_b1a_beta01\"\n",
        "casenum=\"2\"\n",
        "\n",
        "\n",
        "all_path=\"/content/drive/MyDrive/Colab_Notebooks/2023_MEP/0224_res/\"\n",
        "all_path=all_path+mycase+\"/\"\n",
        "\n",
        "\n",
        "path_s=all_path+mycase+\"_s_\"+casenum+\".pkl\"\n",
        "path_path=all_path+mycase+\"_path_\"+casenum+\".pkl\"\n",
        "path_cos=all_path+mycase+\"_cos_\"+casenum+\".pkl\"\n",
        "path_energy=all_path+mycase+\"_energy_\"+casenum+\".pkl\"\n",
        "path_force=all_path+mycase+\"_force_\"+casenum+\".pkl\"\n",
        "path_cosloss=all_path+mycase+\"_coslosss_\"+casenum+\".pkl\"\n",
        "path_lmax=all_path+mycase+\"_lmax_\"+casenum+\".pkl\"\n",
        "path_lg=all_path+mycase+\"_lg_\"+casenum+\".pkl\"\n",
        "#-------------------------------------------------\n",
        "torch.set_printoptions(precision=10)\n",
        "\n",
        "\n",
        "model_Parameters_name = all_path+\"model_MEP_\"+mycase[0:3]+\"_\"+casenum+\"pretrain\"+\".pth\" # Path\n",
        "model_name= all_path+\"model_MEP_\"+mycase+\"_\"+casenum+\".pth\"\n",
        "load_model = False\n",
        "batches = 20000\n",
        "beta = 0.1\n",
        "learning_rate = 1e-4\n",
        "dimension = 2\n",
        "\n",
        "x_lball=-510\n",
        "x_uball=510\n",
        "y_lball=-510\n",
        "y_uball=510\n",
        "\n",
        "x_lb=-170-180\n",
        "x_ub=170-180\n",
        "y_lb=-170+180\n",
        "y_ub=170+180\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device to train\")\n",
        "\n",
        "def kernel(x1, x2):\n",
        "    dist_matrix = torch.sum(x1**2, 1).reshape(-1, 1) + torch.sum(x2**2, 1) - 2 * torch.matmul(x1[:,0].reshape(-1,1), x2[:,0].reshape(1,-1))-2 * torch.matmul(x1[:,1].reshape(-1,1), x2[:,1].reshape(1,-1)) - 2 * torch.matmul(x1[:,2].reshape(-1,1), x2[:,2].reshape(1,-1))-2 * torch.matmul(x1[:,3].reshape(-1,1), x2[:,3].reshape(1,-1))\n",
        "    return 2.85**2 * torch.exp(-0.5 / 0.473 ** 2 * dist_matrix) # not sure\n",
        "\n",
        "def kernel_np(x1, x2):\n",
        "    dist_matrix = np.sum(x1**2, 1).reshape(-1, 1) + np.sum(x2**2, 1) - 2 * np.dot(x1[:,0].reshape(-1,1), x2[:,0].reshape(1,-1))-2 * np.dot(x1[:,1].reshape(-1,1), x2[:,1].reshape(1,-1)) - 2 * np.dot(x1[:,2].reshape(-1,1), x2[:,2].reshape(1,-1))-2 * np.dot(x1[:,3].reshape(-1,1), x2[:,3].reshape(1,-1))\n",
        "    return 2.85**2 * np.exp(-0.5 / 0.473 ** 2 * dist_matrix) # not sure\n",
        "\n",
        "\n",
        "YY = np.load('/content/drive/MyDrive/Colab_Notebooks/2023_MEP/XX.npy')\n",
        "XX = np.load('/content/drive/MyDrive/Colab_Notebooks/2023_MEP/YY.npy')\n",
        "ZZ = np.load('/content/drive/MyDrive/Colab_Notebooks/2023_MEP/ZZ.npy')\n",
        "\n",
        "sinXX=np.sin(XX/180*np.pi)\n",
        "cosXX=np.cos(XX/180*np.pi)\n",
        "\n",
        "sinYY=np.sin(YY/180*np.pi)\n",
        "cosYY=np.cos(YY/180*np.pi)\n",
        "\n",
        "\n",
        "data_x_ori = np.column_stack([sinXX.reshape(35*35,1),cosXX.reshape(35*35,1),sinYY.reshape(35*35,1),cosYY.reshape(35*35,1)])\n",
        "data_y_ori = ZZ.reshape(-1,1)\n",
        "\n",
        "lenx=len(data_x_ori)\n",
        "\n",
        "Kff_ori = kernel_np(data_x_ori, data_x_ori)\n",
        "Kff_inv_ori = np.linalg.inv(Kff_ori + 1e-8 * np.eye(lenx))\n",
        "\n",
        "data_x=s = Variable(torch.from_numpy(data_x_ori),requires_grad= False).to(device)\n",
        "data_y=s = Variable(torch.from_numpy(data_y_ori),requires_grad= False).to(device)\n",
        "\n",
        "mul2_ori=Kff_inv_ori.dot(data_y_ori)\n",
        "\n",
        "mul2=Variable(torch.from_numpy(mul2_ori),requires_grad= False).to(device)\n",
        "\n",
        "\n",
        "def mkdir(path):\n",
        "  folder = os.path.exists(path)\n",
        "  if not folder:\n",
        "    os.makedirs(path)\n",
        "    print(\"---  new folder...  ---\")\n",
        "    print(\"---  OK  ---\")\n",
        "  else:\n",
        "    print(\"---  There is this folder!  ---\")\n",
        "\n",
        "\n",
        "def V(predict_x):\n",
        "    sinxx=torch.sin(predict_x[:,0]/180*np.pi)\n",
        "    cosxx=torch.cos(predict_x[:,0]/180*np.pi)\n",
        "    sinyy=torch.sin(predict_x[:,1]/180*np.pi)\n",
        "    cosyy=torch.cos(predict_x[:,1]/180*np.pi)\n",
        "    predict_x_use=torch.cat([sinxx.reshape(-1,1),cosxx.reshape(-1,1),sinyy.reshape(-1,1),cosyy.reshape(-1,1)],axis=1)\n",
        "    Kfy = kernel(data_x, predict_x_use)\n",
        "    Z = torch.matmul(torch.transpose(Kfy,0,1),mul2)\n",
        "    return Z\n",
        "\n",
        "def V_tensor(x):\n",
        "  x_all=torch.cat(x,axis=1)\n",
        "  res=V(x_all)\n",
        "  return res\n",
        "\n",
        "\n",
        "def V_tensor_grad(x):\n",
        "    grad_Vx=[]\n",
        "    output = V_tensor(x)\n",
        "    for i in range(dimension):\n",
        "      grad_Vx.append(torch.autograd.grad(outputs=output, inputs=x[i], grad_outputs=torch.ones_like(output), create_graph=True)[0])\n",
        "    return grad_Vx\n",
        "\n",
        "\n",
        "def fig_cos_V_force(s,cos2,g,x_pred_list):\n",
        "    fig = plt.figure(figsize=(15,4))\n",
        "    fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.plot(s,cos2,'b.')\n",
        "    plt.ylim(-0.1,1.1)\n",
        "    plt.title(\"Cos^2\")\n",
        "\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.plot(s,V_tensor(x_pred_list).cpu().detach().numpy(), 'b.')\n",
        "    plt.title(\"$Energy$\")\n",
        "\n",
        "    plt.subplot(1,3,3)\n",
        "\n",
        "    force=np.sqrt(np.sum(g*g, axis=1))\n",
        "    plt.plot(s,force, 'b.')\n",
        "    plt.title(\"$Force$\")\n",
        "\n",
        "def fig_loss_batch(plt_batch,loss_batch):\n",
        "    plt.figure(figsize=(5,4))\n",
        "    plt.plot(plt_batch,loss_batch,'b-')\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "\n",
        "def fig_cos(plt_batch,cos_batch,lmax_batch,lg_batch):\n",
        "    fig = plt.figure(figsize=(15,4))\n",
        "    fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.semilogy(plt_batch,cos_batch,'b-')\n",
        "    plt.xlabel(\"Batches\")\n",
        "    plt.ylabel(\"$\\int 1-Cos^2(force,tangent) ds$\")\n",
        "\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.plot(plt_batch,lmax_batch,'b-')\n",
        "    plt.xlabel(\"Batches\")\n",
        "    plt.ylabel(\"$lmax$\")\n",
        "\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.plot(plt_batch,lg_batch,'b-')\n",
        "    plt.xlabel(\"Batches\")\n",
        "    plt.ylabel(\"$l_g$\")\n",
        "\n",
        "def fig_countour(x_pred):\n",
        "    plt.figure(figsize=(10,8))\n",
        "    x = np.linspace(x_lb, x_ub,num=61,endpoint=True)\n",
        "    y = np.linspace(y_lb, y_ub,num=61,endpoint=True)\n",
        "    X,Y = np.meshgrid(x,y)\n",
        "    X_new=X.reshape(-1,1)\n",
        "    Y_new=Y.reshape(-1,1)\n",
        "    XY=np.hstack((X_new,Y_new))\n",
        "    for i in range(dimension-2):\n",
        "      XY=np.hstack((XY,np.zeros(X_new.shape)))\n",
        "\n",
        "    XY_tensor=torch.from_numpy(XY)\n",
        "    X_list = []\n",
        "    for i in range(dimension):\n",
        "      X_list.append(XY_tensor[:, i:i+1].to(device))\n",
        "    Z = V_tensor(X_list)\n",
        "\n",
        "\n",
        "    Z_new=Z.reshape(X.shape).cpu().detach().numpy()\n",
        "\n",
        "\n",
        "\n",
        "    plt.figure()\n",
        "    CS = plt.contourf(X,Y,Z_new,50,cmap=mpl.cm.jet)\n",
        "    plt.colorbar(CS)\n",
        "    x_plot=x_pred.cpu().detach().numpy()\n",
        "    plt.plot(x_plot[:,0],x_plot[:,1],\"r.\",markersize=5)\n",
        "    plt.xlim((x_lb,x_ub))\n",
        "    plt.ylim((y_lb,y_ub))\n",
        "    plt.xlabel('$x_1$')\n",
        "    plt.ylabel('$x_2$')\n",
        "\n",
        "\n",
        "def fig_countour_all(x_pred):\n",
        "    plt.figure(figsize=(10,8))\n",
        "    x = np.linspace(x_lball, x_uball,num=61,endpoint=True)\n",
        "    y = np.linspace(y_lball, y_uball,num=61,endpoint=True)\n",
        "    X,Y = np.meshgrid(x,y)\n",
        "    X_new=X.reshape(-1,1)\n",
        "    Y_new=Y.reshape(-1,1)\n",
        "    XY=np.hstack((X_new,Y_new))\n",
        "    for i in range(dimension-2):\n",
        "      XY=np.hstack((XY,np.zeros(X_new.shape)))\n",
        "\n",
        "    XY_tensor=torch.from_numpy(XY)\n",
        "    X_list = []\n",
        "    for i in range(dimension):\n",
        "      X_list.append(XY_tensor[:, i:i+1].to(device))\n",
        "    Z = V_tensor(X_list)\n",
        "\n",
        "\n",
        "    Z_new=Z.reshape(X.shape).cpu().detach().numpy()\n",
        "\n",
        "\n",
        "\n",
        "    plt.figure()\n",
        "    CS = plt.contourf(X,Y,Z_new,50,cmap=mpl.cm.jet)\n",
        "    plt.colorbar(CS)\n",
        "    x_plot=x_pred.cpu().detach().numpy()\n",
        "    plt.plot(x_plot[:,0],x_plot[:,1],\"r.\",markersize=5)\n",
        "    plt.xlim((x_lball,x_uball))\n",
        "    plt.ylim((y_lball,y_uball))\n",
        "    plt.xlabel('$x_1$')\n",
        "    plt.ylabel('$x_2$')\n",
        "\n",
        "\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self,st,ed):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_tanh_stack = nn.Sequential(\n",
        "            nn.Linear(1, 100),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(100, 200),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(200, 200),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(200, 200),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(200, 100),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(100, dimension)\n",
        "        )\n",
        "        self.startpoint=Variable(torch.from_numpy(np.array([st])),requires_grad=False).to(device)\n",
        "        self.endpoint=Variable(torch.from_numpy(np.array([ed])),requires_grad=False).to(device)\n",
        "\n",
        "\n",
        "    def forward(self, s):\n",
        "        s = self.flatten(s)\n",
        "        x_pred = self.linear_tanh_stack(s)\n",
        "        out=s*(1-s)*x_pred + (1-s)*self.startpoint + s*self.endpoint\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "def train(model):\n",
        "    loss_batch=[]\n",
        "    plt_batch=[]\n",
        "    cos_batch=[]\n",
        "\n",
        "    lg_batch=[]\n",
        "    lmax_batch=[]\n",
        "    if load_model:\n",
        "        model.load_state_dict(torch.load(model_Parameters_name))\n",
        "\n",
        "    for i in range(batches):\n",
        "\n",
        "        learning_rate=1e-3\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "        s = np.random.uniform(0.001,0.999,(500,1))\n",
        "        s = Variable(torch.from_numpy(s),requires_grad=True).to(device)\n",
        "\n",
        "        x_pred = model(s)\n",
        "        x_pred_list = []\n",
        "        for n in range(dimension):\n",
        "            x_pred_list.append(x_pred[:, n:n+1])\n",
        "\n",
        "        v = V_tensor(x_pred_list)\n",
        "        gradx_list=[]\n",
        "        gradgx_list=[]\n",
        "        for n in range(dimension):\n",
        "            gradx_list.append(torch.autograd.grad(outputs=x_pred_list[n],inputs=s,grad_outputs=torch.ones_like(s),create_graph=True)[0])\n",
        "            gradgx_list.append(torch.autograd.grad(outputs=gradx_list[n],inputs=s,grad_outputs=torch.ones_like(s),create_graph=True)[0])\n",
        "\n",
        "        partial_s_x = torch.cat(gradx_list, axis=1)\n",
        "        dot_partial_s_x = torch.sqrt(torch.sum(partial_s_x*partial_s_x, axis=1, keepdim=False))\n",
        "        loss_1=1/beta*torch.log(torch.mean(torch.exp((v+0)*beta)*dot_partial_s_x))\n",
        "\n",
        "        g_all = V_tensor_grad(x_pred_list)\n",
        "        g=torch.cat(g_all, axis=1)\n",
        "        cos2 = (torch.sum(partial_s_x*g,axis=1, keepdim=True)/(torch.sum(g*g, axis=1, keepdim=True)**0.5*torch.sum(partial_s_x*partial_s_x, axis=1, keepdim=True)**0.5))**2\n",
        "        loss_2 = torch.mean(1-cos2)\n",
        "\n",
        "        cons=0\n",
        "        for n in range(dimension):\n",
        "            cons += torch.sum(gradx_list[n]*gradgx_list[n], axis=1, keepdim=True)\n",
        "\n",
        "        loss_3 = torch.mean(cons**2)\n",
        "\n",
        "        dot_g= torch.sqrt(torch.sum(g*g, axis=1, keepdim=False))\n",
        "        loss_4=torch.mean(dot_g*dot_partial_s_x)\n",
        "\n",
        "        alpha3=0.000000001\n",
        "        alpha1=1\n",
        "\n",
        "        alpha4=0\n",
        "        loss = alpha1*loss_1 +alpha4*loss_4+alpha3*loss_3\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i) % 50 == 0:\n",
        "            ss = np.linspace(0.001,0.999,1000,endpoint=True)\n",
        "            ss = ss.reshape(-1,1)\n",
        "            ss = Variable(torch.from_numpy(ss),requires_grad=True).to(device)\n",
        "            xx = model(ss)\n",
        "            gradx_list_plot=[]\n",
        "            x_pred_list_plot = []\n",
        "            for n in range(dimension):\n",
        "                x_pred_list_plot.append(xx[:, n:n+1])\n",
        "            for n in range(dimension):\n",
        "                gradx_list_plot.append(torch.autograd.grad(outputs=x_pred_list_plot[n],inputs=ss,grad_outputs=torch.ones_like(ss),create_graph=True)[0]) # First order derivative of x w.r.t s\n",
        "            partial_s_x_plot = torch.cat(gradx_list_plot, axis=1)\n",
        "\n",
        "            g_all_plot = V_tensor_grad(x_pred_list_plot)\n",
        "            g_plot=torch.cat(g_all_plot, axis=1)\n",
        "            cos2_plot = (torch.sum(partial_s_x_plot*g_plot,axis=1, keepdim=True)/(torch.sum(g_plot*g_plot, axis=1, keepdim=True)**0.5*torch.sum(partial_s_x_plot*partial_s_x_plot, axis=1, keepdim=True)**0.5))**2\n",
        "            cos_plot_loss = torch.mean(1-cos2_plot)\n",
        "            cos_batch.append(cos_plot_loss.item())\n",
        "\n",
        "            U_max=torch.max(V_tensor(x_pred_list_plot))\n",
        "            lmax_batch.append(U_max.item())\n",
        "\n",
        "            dot_partial_s_x_plot = torch.sqrt(torch.sum(partial_s_x_plot*partial_s_x_plot, axis=1, keepdim=False))\n",
        "            dot_g_plot= torch.sqrt(torch.sum(g_plot*g_plot, axis=1, keepdim=False))\n",
        "            lg=torch.mean(dot_g_plot*dot_partial_s_x_plot)\n",
        "\n",
        "            lg_batch.append(lg.item())\n",
        "\n",
        "            vv = V_tensor(x_pred_list_plot)\n",
        "            partial_s_x_plot=torch.cat(gradx_list_plot, axis=1)\n",
        "            dot_partial_s_x_plot = torch.sqrt(torch.sum(partial_s_x_plot*partial_s_x_plot, axis=1, keepdim=False))\n",
        "            loss_beta_plot=1/beta*torch.log(torch.mean(torch.exp(vv*beta)*dot_partial_s_x_plot))\n",
        "            ratio=torch.max(dot_partial_s_x_plot)/torch.min(dot_partial_s_x_plot)\n",
        "\n",
        "            loss, batch = alpha1*loss_1.item() + alpha4*loss_4.item() + alpha3*loss_3.item(), i\n",
        "            print(f'batches: {batch+1}')\n",
        "            print(f'loss1: {alpha1*loss_1} loss4: {alpha4*loss_4} loss3: {alpha3*loss_3} max/min: {ratio.item()} lg: {lg.item()}')\n",
        "\n",
        "            loss_batch.append(loss)\n",
        "            plt_batch.append(i+1)\n",
        "            plt.figure()\n",
        "\n",
        "        if (i+1) % 500 == 0:\n",
        "            print(\"------>beta_loss=\",loss_beta_plot.item(),\"beta=\",beta)\n",
        "            print(\"cos_plot_loss.item()=\",cos_plot_loss.item())\n",
        "            fig_cos(plt_batch,cos_batch,lmax_batch,lg_batch)\n",
        "            fig_loss_batch(plt_batch,loss_batch)\n",
        "            fig_cos_V_force(s.cpu().detach().numpy(),cos2.cpu().detach().numpy(),g.cpu().detach().numpy(),x_pred_list)  # Why [1:-1]\n",
        "\n",
        "            fig_countour(x_pred)\n",
        "            fig_countour_all(x_pred)\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "            torch.save(model.state_dict(), model_name)\n",
        "            print(\"Saved PyTorch Model State to \" +str(model_name))\n",
        "\n",
        "    output = open(path_s, 'wb')\n",
        "    pickle.dump(s.cpu().detach().numpy(),output)\n",
        "    output.close()\n",
        "\n",
        "    output = open(path_path, 'wb')\n",
        "    pickle.dump(x_pred.cpu().detach().numpy(),output)\n",
        "    output.close()\n",
        "\n",
        "    output = open(path_cos, 'wb')\n",
        "    pickle.dump(cos2.cpu().detach().numpy(),output)\n",
        "    output.close()\n",
        "\n",
        "    output = open(path_energy, 'wb')\n",
        "    pickle.dump(V_tensor(x_pred_list).cpu().detach().numpy(),output)\n",
        "    output.close()\n",
        "\n",
        "    output = open(path_force, 'wb')\n",
        "    pickle.dump(np.sqrt(np.sum(g.cpu().detach().numpy()*g.cpu().detach().numpy(), axis=1)),output)\n",
        "    output.close()\n",
        "\n",
        "    output = open(path_cosloss, 'wb')\n",
        "    pickle.dump(cos_batch,output)\n",
        "    output.close()\n",
        "\n",
        "    output = open(path_lg, 'wb')\n",
        "    pickle.dump(lg_batch,output)\n",
        "    output.close()\n",
        "\n",
        "    output = open(path_lmax, 'wb')\n",
        "    pickle.dump(lmax_batch,output)\n",
        "    output.close()\n",
        "\n",
        "    return\n",
        "\n",
        "def train_pre(model):\n",
        "    for i in range(2000):\n",
        "      a=np.array([-81.0640995,70.67714575])\n",
        "      b=np.array([69.43047688,-67.71500979])\n",
        "\n",
        "      c=(a+b)/2\n",
        "      r=np.sqrt(np.sum((a-b)**2))/2\n",
        "\n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "      t = np.random.uniform(0,1,(500,1))\n",
        "      t = Variable(torch.from_numpy(t),requires_grad=True).to(device)\n",
        "\n",
        "      xy=model(t)\n",
        "      x,y=torch.split(xy,[1,1],dim=1)\n",
        "\n",
        "      loss=torch.mean((x-c[0]-r*torch.cos(np.pi*t+2.398))**2+(y-c[1]-r*torch.sin(np.pi*t+2.398))**2)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      if i % 500==0:\n",
        "        print(loss.item())\n",
        "\n",
        "    return model\n",
        "\n",
        "if __name__=='__main__':\n",
        "    MEPpass_start_point=[-150.70424501 ,168.84224223]+[0]*(dimension-2)#\n",
        "    MEPpass_end_point=[69.43047688-360,-67.71500979+360]+[0]*(dimension-2)\n",
        "\n",
        "    mkdir(all_path)\n",
        "\n",
        "    model = NeuralNetwork(MEPpass_start_point,MEPpass_end_point).to(device)\n",
        "    model = model.double()\n",
        "    #model = train_pre(model)\n",
        "    train(model)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hx-nYO_7r2nz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}