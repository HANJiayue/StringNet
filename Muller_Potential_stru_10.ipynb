{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58ihB-Z1O6ZZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import matplotlib as mpl\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from scipy.linalg import qr\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "mycase=\"mp_prime_stru_10\"\n",
        "casenum=\"14\"\n",
        "\n",
        "\n",
        "all_path=\"/content/drive/MyDrive/Colab_Notebooks/2023_MEP/1107_data/\"\n",
        "\n",
        "path_s=all_path+mycase+\"_s_\"+casenum+\".pkl\"\n",
        "path_path=all_path+mycase+\"_path_\"+casenum+\".pkl\"\n",
        "path_cos=all_path+mycase+\"_cos_\"+casenum+\".pkl\"\n",
        "path_energy=all_path+mycase+\"_energy_\"+casenum+\".pkl\"\n",
        "path_force=all_path+mycase+\"_force_\"+casenum+\".pkl\"\n",
        "path_cosloss=all_path+mycase+\"_coslosss_\"+casenum+\".pkl\"\n",
        "path_Q=all_path+mycase[0:2]+\"_Q_\"+casenum+\".pkl\"\n",
        "path_lmax=all_path+mycase+\"_lmax_\"+casenum+\".pkl\"\n",
        "path_lg=all_path+mycase+\"_lg_\"+casenum+\".pkl\"\n",
        "path_time=all_path+mycase+\"_time_\"+casenum+\".pkl\"\n",
        "\n",
        "model_name= all_path+\"/model_MEP_\"+mycase+\"_\"+casenum+\".pth\"\n",
        "model_Parameters_name = all_path+\"model_MEP_\"+mycase[0:2]+\"_\"+casenum+\"pretrain\"+\".pth\" # Path\n",
        "\n",
        "load_model = False\n",
        "batches = 20000\n",
        "beta = 10\n",
        "learning_rate = 1e-3\n",
        "dimension = 10\n",
        "ad=0\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device to train\")\n",
        "\n",
        "pkl_file = open(path_Q, 'rb')\n",
        "Q = pickle.load(pkl_file)\n",
        "pkl_file.close()\n",
        "Q_ten=torch.tensor(Q).to(device)\n",
        "\n",
        "x_lb=-1.5\n",
        "x_ub=0.9\n",
        "y_lb=-0.5\n",
        "y_ub=1.9\n",
        "\n",
        "alpha1=1\n",
        "alpha2=10\n",
        "alpha3=2.5\n",
        "\n",
        "def V_tensor_plot(x):\n",
        "  a = [ -1, -1, -6.5, 0.7]\n",
        "  b = [0, 0, 11, 0.6]\n",
        "  c = [ -10, -10, -6.5, 0.7]\n",
        "  D = [ -200, -100, -170, 15]\n",
        "  X = [1, 0, -0.5, -1]\n",
        "  Y = [0, 0.5, 1.5, 1]\n",
        "  sigma=0.5\n",
        "\n",
        "  res=0\n",
        "  for i in range(4):\n",
        "    res=res+D[i]*torch.exp(a[i]*(x[0]-X[i])**2+b[i]*(x[0]-X[i])*(x[1]-Y[i])+c[i]*(x[1]-Y[i])**2)\n",
        "  for i in range(dimension-2):\n",
        "    res=res+1/(2*sigma**2)*x[i+2]**2\n",
        "  return res\n",
        "\n",
        "\n",
        "def V_tensor_and_grad(x):\n",
        "    global Q_ten\n",
        "    a = [ -1, -1, -6.5, 0.7]\n",
        "    b = [0, 0, 11, 0.6]\n",
        "    c = [ -10, -10, -6.5, 0.7]\n",
        "    D = [ -200, -100, -170, 15]\n",
        "    X = [1, 0, -0.5, -1]\n",
        "    Y = [0, 0.5, 1.5, 1]\n",
        "    sigma=0.5\n",
        "\n",
        "    xx=torch.cat(x,dim=1)\n",
        "    xx=torch.matmul(xx,Q_ten)\n",
        "    x_temp=xx[:,0:dimension]\n",
        "\n",
        "    x_all=[]\n",
        "    for i in range(dimension):\n",
        "      x_all.append(x_temp[:,i:i+1])\n",
        "\n",
        "    res=0\n",
        "    for i in range(4):\n",
        "      res=res+D[i]*torch.exp(a[i]*(x_all[0]-X[i])**2+b[i]*(x_all[0]-X[i])*(x_all[1]-Y[i])+c[i]*(x_all[1]-Y[i])**2)\n",
        "    for i in range(dimension-2):\n",
        "      res=res+1/(2*sigma**2)*x_all[i+2]**2\n",
        "\n",
        "    grad_Vx=[]\n",
        "    for i in range(dimension+ad):\n",
        "      grad_Vx.append(torch.autograd.grad(outputs=res, inputs=x[i], grad_outputs=torch.ones_like(res), create_graph=True)[0])\n",
        "\n",
        "    return res,grad_Vx\n",
        "\n",
        "\n",
        "def fig_cos_V_force(s,cos2,g,x_pred_list):\n",
        "    fig = plt.figure(figsize=(15,4))\n",
        "    fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.plot(s,cos2,'b.')\n",
        "    plt.ylim(-0.1,1.1)\n",
        "    plt.title(\"$Cos^2$\")\n",
        "\n",
        "    vplot,gg =V_tensor_and_grad(x_pred_list)\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.plot(s,vplot.cpu().detach().numpy(), 'b.')\n",
        "    plt.title(\"$Energy$\")\n",
        "\n",
        "    plt.subplot(1,3,3)\n",
        "\n",
        "    force=np.sqrt(np.sum(g*g, axis=1))\n",
        "    plt.plot(s,force, 'b.')\n",
        "    plt.title(\"$Force$\")\n",
        "\n",
        "def fig_loss_batch(plt_batch,loss_batch):\n",
        "    plt.figure(figsize=(5,4))\n",
        "    plt.plot(plt_batch,loss_batch,'b-')\n",
        "    plt.xlabel(\"Batches\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "\n",
        "def fig_cos(plt_batch,cos_batch,lmax_batch,lg_batch,time_batch):\n",
        "    fig = plt.figure(figsize=(15,4))\n",
        "    fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.semilogy(plt_batch,cos_batch,'b-')\n",
        "    plt.xlabel(\"Batches\")\n",
        "    plt.ylabel(\"$\\int 1-Cos^2(force,tangent) ds$\")\n",
        "\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.plot(plt_batch,lmax_batch,'b-')\n",
        "    plt.xlabel(\"Batches\")\n",
        "    plt.ylabel(\"$lmax$\")\n",
        "\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.plot(plt_batch,lg_batch,'b-')\n",
        "    plt.xlabel(\"Batches\")\n",
        "    plt.ylabel(\"$l_g$\")\n",
        "\n",
        "    fig = plt.figure(figsize=(15,4))\n",
        "    fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.semilogy(time_batch,cos_batch,'b-')\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"$\\int 1-Cos^2(force,tangent) ds$\")\n",
        "\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.plot(time_batch,lmax_batch,'b-')\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"$lmax$\")\n",
        "\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.plot(time_batch,lg_batch,'b-')\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"$l_g$\")\n",
        "\n",
        "def fig_countour(x_pred):\n",
        "    global Q_ten\n",
        "    plt.figure(figsize=(5,4))\n",
        "    x = np.linspace(x_lb, x_ub,num=50,endpoint=True)#50\n",
        "    y = np.linspace(y_lb, y_ub,num=50,endpoint=True)\n",
        "    X,Y = np.meshgrid(x,y)\n",
        "    X_new=X.reshape(-1,1)\n",
        "    Y_new=Y.reshape(-1,1)\n",
        "    XY=np.hstack((X_new,Y_new))\n",
        "    for i in range(dimension-2):\n",
        "      XY=np.hstack((XY,np.zeros(X_new.shape)))\n",
        "\n",
        "    XY_tensor=torch.from_numpy(XY)\n",
        "    X_list = []\n",
        "    for i in range(dimension+ad):\n",
        "      X_list.append(XY_tensor[:, i:i+1])\n",
        "\n",
        "    Z = V_tensor_plot(X_list)\n",
        "    Z_new=Z.reshape(X.shape).cpu().detach().numpy()\n",
        "\n",
        "    plt.figure()\n",
        "    CS = plt.contourf(X,Y,Z_new,50,cmap=mpl.cm.jet)\n",
        "    plt.colorbar(CS)\n",
        "\n",
        "    xx=torch.matmul(x_pred,Q_ten)\n",
        "    x_temp=xx[:,0:dimension]\n",
        "\n",
        "    x_plot=x_temp.cpu().detach().numpy()\n",
        "    plt.plot(x_plot[:,0],x_plot[:,1],\"r.\",markersize=5)\n",
        "    plt.xlim((x_lb,x_ub))\n",
        "    plt.ylim((y_lb,y_ub))\n",
        "    plt.xlabel('$x_1$')\n",
        "    plt.ylabel('$x_2$')\n",
        "\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self,st,ed):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.stack_all=nn.ModuleList()\n",
        "        for i in range(dimension+ad):\n",
        "          self.stack_all.append(nn.Linear(1, 6))\n",
        "          self.stack_all.append(nn.Sigmoid())\n",
        "          for j in range(4):\n",
        "            self.stack_all.append(nn.Linear(6, 6))\n",
        "            self.stack_all.append(nn.Sigmoid())\n",
        "          self.stack_all.append(nn.Linear(6, 1))\n",
        "\n",
        "        self.startpoint=Variable(torch.from_numpy(st),requires_grad=False).to(device)\n",
        "        self.endpoint=Variable(torch.from_numpy(ed),requires_grad=False).to(device)\n",
        "\n",
        "\n",
        "    def forward(self, s):\n",
        "        s = self.flatten(s)\n",
        "        x_all=[]\n",
        "        for i in range(dimension+ad):\n",
        "          xx=self.stack_all[i*11](s)\n",
        "          for j in range(10):\n",
        "            xx=self.stack_all[i*11+j+1](xx)\n",
        "          x_all.append(xx)\n",
        "        x_pred = torch.cat(x_all,1)\n",
        "        out=s*(1-s)*x_pred + (1-s)*self.startpoint + s*self.endpoint\n",
        "        return out\n",
        "\n",
        "def train(model):\n",
        "    loss_batch=[]\n",
        "    plt_batch=[]\n",
        "    cos_batch=[]\n",
        "\n",
        "    lg_batch=[]\n",
        "    lmax_batch=[]\n",
        "\n",
        "    time_batch=[]\n",
        "    t1=time.time()\n",
        "    if load_model:\n",
        "        model.load_state_dict(torch.load(model_Parameters_name))\n",
        "\n",
        "    for i in range(batches):\n",
        "        if i<3000:\n",
        "          alpha1=1\n",
        "          alpha4=0.001\n",
        "          alpha3=0.1\n",
        "        elif i<10000:\n",
        "          alpha1=0.1\n",
        "          alpha4=10\n",
        "          alpha3=0.1\n",
        "        else:\n",
        "          alpha1=0\n",
        "          alpha4=10\n",
        "          alpha3=0.1\n",
        "\n",
        "        if i<6000:\n",
        "          learning_rate=5e-4\n",
        "        elif i<15000:\n",
        "          learning_rate=1e-4\n",
        "        else:\n",
        "          learning_rate=1e-5\n",
        "\n",
        "\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "        s = np.random.uniform(0.001,0.999,(250,1))\n",
        "\n",
        "        s = Variable(torch.from_numpy(s),requires_grad=True).to(device)\n",
        "        x_pred = model(s)\n",
        "\n",
        "        x_pred_list = []\n",
        "        for n in range(dimension+ad):\n",
        "            x_pred_list.append(x_pred[:, n:n+1])\n",
        "\n",
        "        v,g_all = V_tensor_and_grad(x_pred_list)\n",
        "\n",
        "        gradx_list=[]\n",
        "        gradgx_list=[]\n",
        "        for n in range(dimension+ad):\n",
        "            gradx_list.append(torch.autograd.grad(outputs=x_pred_list[n],inputs=s,grad_outputs=torch.ones_like(s),create_graph=True)[0]) # First order derivative of x w.r.t s\n",
        "            gradgx_list.append(torch.autograd.grad(outputs=gradx_list[n],inputs=s,grad_outputs=torch.ones_like(s),create_graph=True)[0]) # Second order derivative of x w.r.t s\n",
        "\n",
        "        partial_s_x = torch.cat(gradx_list, axis=1)\n",
        "        dot_partial_s_x = torch.sqrt(torch.sum(partial_s_x*partial_s_x, axis=1, keepdim=False)) #s对神经网络的一阶导数的数量积\n",
        "        loss_1=1/beta*torch.log(torch.mean(torch.exp(v*beta)))\n",
        "\n",
        "        g=torch.cat(g_all, axis=1)\n",
        "        cos2 = (torch.sum(partial_s_x*g,axis=1, keepdim=True)/(torch.sum(g*g, axis=1, keepdim=True)**0.5*torch.sum(partial_s_x*partial_s_x, axis=1, keepdim=True)**0.5))**2\n",
        "        loss_2 = torch.mean(1-cos2)\n",
        "\n",
        "        cons=0\n",
        "        for n in range(dimension+ad):\n",
        "            cons += torch.sum(gradx_list[n]*gradgx_list[n], axis=1, keepdim=True)\n",
        "        loss_3 = torch.mean(cons**2)\n",
        "\n",
        "        dot_g= torch.sqrt(torch.sum(g*g, axis=1, keepdim=False))\n",
        "        loss_4=torch.mean(dot_g*dot_partial_s_x)\n",
        "\n",
        "        loss = alpha1*loss_1 +alpha4*loss_4+alpha3*loss_3\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i) % 50 == 0:\n",
        "            ss = np.linspace(0.001,0.999,1000,endpoint=True)\n",
        "\n",
        "            ss = ss.reshape(-1,1)\n",
        "            ss = Variable(torch.from_numpy(ss),requires_grad=True).to(device)\n",
        "            xx = model(ss)\n",
        "            gradx_list_plot=[]\n",
        "            x_pred_list_plot = []\n",
        "            for n in range(dimension+ad):\n",
        "                x_pred_list_plot.append(xx[:, n:n+1])\n",
        "            for n in range(dimension+ad):\n",
        "                gradx_list_plot.append(torch.autograd.grad(outputs=x_pred_list_plot[n],inputs=ss,grad_outputs=torch.ones_like(ss),create_graph=True)[0]) # First order derivative of x w.r.t s\n",
        "            partial_s_x_plot = torch.cat(gradx_list_plot, axis=1)\n",
        "\n",
        "            VVV,g_all_plot = V_tensor_and_grad(x_pred_list_plot)\n",
        "            g_plot=torch.cat(g_all_plot, axis=1)\n",
        "            cos2_plot = (torch.sum(partial_s_x_plot*g_plot,axis=1, keepdim=True)/(torch.sum(g_plot*g_plot, axis=1, keepdim=True)**0.5*torch.sum(partial_s_x_plot*partial_s_x_plot, axis=1, keepdim=True)**0.5))**2\n",
        "            cos_plot_loss = torch.mean(1-cos2_plot)\n",
        "            cos_batch.append(cos_plot_loss.item())\n",
        "\n",
        "            lmax_batch.append(torch.max(VVV).item())\n",
        "\n",
        "            dot_partial_s_x_plot = torch.sqrt(torch.sum(partial_s_x_plot*partial_s_x_plot, axis=1, keepdim=False))\n",
        "            dot_g_plot= torch.sqrt(torch.sum(g_plot*g_plot, axis=1, keepdim=False))\n",
        "            lg=torch.mean(dot_g_plot*dot_partial_s_x_plot)\n",
        "\n",
        "            lg_batch.append(lg.item())\n",
        "\n",
        "            t2=time.time()\n",
        "            time_batch.append(t2-t1)\n",
        "\n",
        "            loss, batch = alpha1*loss_1.item() + alpha4*loss_4.item() + alpha3*loss_3.item(), i\n",
        "            print(f'batches: {batch+1}')\n",
        "            print(f'loss1: {alpha1*loss_1} loss4: {alpha4*loss_4} loss3: {alpha3*loss_3}')\n",
        "            loss_batch.append(loss)\n",
        "            plt_batch.append(i+1)\n",
        "            plt.figure()\n",
        "\n",
        "        if (i+1) % 500 == 0:\n",
        "            print(\"cos_plot_loss.item()=\",cos_plot_loss.item())\n",
        "            fig_cos(plt_batch,cos_batch,lmax_batch,lg_batch,time_batch)\n",
        "            fig_loss_batch(plt_batch,loss_batch)\n",
        "            fig_cos_V_force(s.cpu().detach().numpy(),cos2.cpu().detach().numpy(),g.cpu().detach().numpy(),x_pred_list)  # Why [1:-1\n",
        "            fig_countour(x_pred)\n",
        "            plt.show()\n",
        "\n",
        "            torch.save(model.state_dict(), model_name)\n",
        "            print(\"Saved PyTorch Model State to \" +\"model_MEP.pth\")\n",
        "\n",
        "    output = open(path_s, 'wb')\n",
        "    pickle.dump(s.cpu().detach().numpy(),output)\n",
        "    output.close()\n",
        "\n",
        "    output = open(path_path, 'wb')\n",
        "    pickle.dump(x_pred.cpu().detach().numpy(),output)\n",
        "    output.close()\n",
        "\n",
        "    output = open(path_cos, 'wb')\n",
        "    pickle.dump(cos2.cpu().detach().numpy(),output)\n",
        "    output.close()\n",
        "\n",
        "    output = open(path_energy, 'wb')\n",
        "    VV,gg=V_tensor_and_grad(x_pred_list)\n",
        "    pickle.dump(VV.cpu().detach().numpy(),output)\n",
        "    output.close()\n",
        "\n",
        "    output = open(path_force, 'wb')\n",
        "    pickle.dump(np.sqrt(np.sum(g.cpu().detach().numpy()*g.cpu().detach().numpy(), axis=1)),output)\n",
        "    output.close()\n",
        "\n",
        "    output = open(path_cosloss, 'wb')\n",
        "    pickle.dump(cos_batch,output)\n",
        "    output.close()\n",
        "\n",
        "    output = open(path_lg, 'wb')\n",
        "    pickle.dump(lg_batch,output)\n",
        "    output.close()\n",
        "\n",
        "    output = open(path_lmax, 'wb')\n",
        "    pickle.dump(lmax_batch,output)\n",
        "    output.close()\n",
        "\n",
        "    output = open(path_time, 'wb')\n",
        "    pickle.dump(time_batch,output)\n",
        "    output.close()\n",
        "    return\n",
        "\n",
        "def train_pre(model):\n",
        "    for i in range(0):\n",
        "      a=np.array([-81.0640995,70.67714575])\n",
        "      b=np.array([69.43047688,-67.71500979])\n",
        "\n",
        "      c=(a+b)/2\n",
        "      r=np.sqrt(np.sum((a-b)**2))/2\n",
        "\n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "      t = np.random.uniform(0,1,(500,1))\n",
        "      t = Variable(torch.from_numpy(t),requires_grad=True).to(device)\n",
        "\n",
        "      xy=model(t)\n",
        "      x,y=torch.split(xy,[1,1],dim=1)\n",
        "\n",
        "      loss=torch.mean((x-c[0]-r*torch.cos(np.pi*t+2.398))**2+(y-c[1]-r*torch.sin(np.pi*t+2.398))**2)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      if i % 500==0:\n",
        "        print(loss.item())\n",
        "    torch.save(model.state_dict(), model_Parameters_name)\n",
        "\n",
        "    return model\n",
        "\n",
        "if __name__=='__main__':\n",
        "    MEPpass_start_point=[6.23499399e-01,2.80377512e-02]+[0]*(dimension+ad-2)\n",
        "    MEPpass_end_point=[-5.58223673e-01,1.44172580e+00]+[0]*(dimension+ad-2)\n",
        "\n",
        "    MEPpass_start_point=np.array(MEPpass_start_point)\n",
        "    MEPpass_end_point=np.array(MEPpass_end_point)\n",
        "\n",
        "    MEPpass_start_point_new=np.matmul(Q,MEPpass_start_point.reshape(-1,1))\n",
        "    MEPpass_end_point_new=np.matmul(Q,MEPpass_end_point.reshape(-1,1))\n",
        "\n",
        "\n",
        "\n",
        "    model = NeuralNetwork(MEPpass_start_point_new.reshape(1,-1),MEPpass_end_point_new.reshape(1,-1)).to(device).double()\n",
        "    #model = train_pre(model)\n",
        "    train(model)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}